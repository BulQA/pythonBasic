Big О нотация, или Как оценить сложность алгоритма
С этого материала начинается отдельный цикл по теме «Алгоритмы и структуры данных».
Понимание алгоритмов — важный навык для решения задач, в том числе в тестовых заданиях
и на технических собеседованиях. Серия материалов об алгоритмах поможет разобраться в
основах и даст минимально необходимый объём знаний и умений — это базовый уровень понимания
темы, однако дальнейшее профессиональное развитие может потребовать более глубокого погружения.

Зная основы, вы:
⦁	начнёте задумываться об эффективности кода, который пишете;
⦁	глубже поймёте работу стандартных структур данных (а значит, сможете правильно выбирать
структуры для своих задач);
⦁	познакомитесь с новыми структурами данных и узнаете об их преимуществах;
⦁	станете более ценным соискателем, так как работодатели ценят людей, пишущих эффективный код;
⦁	сможете улучшить свои навыки программирования на Python, анализируя реализации алгоритмов и
структур данных, о которых пойдёт речь.

Что вы узнаете
В этом материале вы:
⦁	разберёте базовые понятия темы «Алгоритмы и структуры данных»;
⦁	узнаете, как принято измерять эффективность алгоритма и зачем это делать;
⦁	на наглядных примерах рассмотрите разницу между эффективным и неэффективным алгоритмами.

Что такое алгоритм
Прежде чем приступить к оценке сложности алгоритма, стоит определиться, что именно мы называем алгоритмом.
Если говорить о повседневной жизни, то алгоритм — это просто набор действий, который нужно выполнить,
чтобы получить задуманный результат. Захотели воды? Нужно пойти на кухню, взять стакан, ёмкость с водой
и так далее.
В контексте программирования суть алгоритма остаётся той же, но добавляется важное уточнение: этот набор
действий (инструкций) должен быть понятен исполнителю, то есть компьютеру.
Таким образом,алгоритм— набор действий, который компьютер может выполнить и который приведёт к нужному
нам результату. Пожалуй, самый популярный пример алгоритма — сортировка, при этом любое из ваших решений
тоже будет алгоритмом.

Как измерить сложность алгоритма
Перейдём к оценке сложности алгоритма. Если бы перед нами стояла такая задача, интуитивно мы могли бы
измерить время выполнения двух алгоритмов и однозначно сказать, какой из них лучше. В некотором смысле мы
были бы правы, но этот подход упускает принципиально важную деталь — алгоритм может обрабатывать разные
объёмы данных.
Проблема заключается в том, что один алгоритм может быстрее обработать десять чисел, но в задаче с 1 млн
чисел он окажется медленнее, так как второй алгоритм может быть лучше оптимизирован именно под работу с
большим количеством чисел.
Что измерять вместо времени — количество выполненных действий? Тоже логичный вариант и тоже не совсем нам
подходит, ведь для разных объёмов данных придётся указывать разное количество выполненных действий.
Так как простые и очевидные варианты не подходят, приходится придумывать вариант посложнее, который
поможет оценить работу алгоритма с разными объёмами данных. Нужно описать связь между количеством
операций и элементов. Если брать пример из математики, это позволяет сделать функция, в общем виде
она может выглядеть так:
Y = f(X) — значение игрека будет зависеть от значения икса по определённому правилу.
Пример такого правила может быть простым:
Y = 2 * X — игрек будет всегда в два раза больше икса.
Пример может быть сложнее:
Y = X ** 2 + 7 * X – 5
Зависимость может быть любой — главное, что у нас появился инструмент, с помощью которого можно описать
такую зависимость.
Например, мы можем сравнить:
Y = 1 000 * X
и
Y = 10 000 * X
Если Y — это зарплата, а X — количество отработанных дней, мы и без калькулятора сможем сделать выбор
между этими двумя предложениями :) В нашем случае Y — количество действий, которые алгоритм должен
совершить, а X — количество элементов, которые он должен обработать.
Если возьмём простую зависимость:
Y = 2 * X,
то по такому описанию поймём, что алгоритм на каждый элемент выполняет по два действия. А значит, если
нам надо будет обработать 100 элементов, алгоритм сделает это за 200 действий.
Поговорим о том, как это должно выглядеть. X, Y и f(X) чаще используются в школьных задачах. Когда речь
заходит об оценке сложности алгоритмов, принято использовать следующие обозначения:
⦁	n — количество элементов;
⦁	O(n) — функция от количества элементов [по сути, это и есть Y или f(X)].
Буквы другие, но суть остаётся той же — они сразу позволяют понять, что речь идёт озадаче оценки сложности
алгоритмов.

Типичные примеры O-нотации (сложности алгоритмов)
Сразу хочется успокоить: никаких сложных точных уравнений писать не нужно. Есть несколько общих вариантов
зависимости, которые позволяют примерно оценить скорость работы алгоритма (от быстрой к медленной).
По сути, нам не столько важно конкретное количество действий алгоритма, сколько важенпорядок роста.
То есть мы отвечаем на вопросы вида: «Если алгоритм обработает 10 элементов за X действий, во сколько
раз больше действий ему понадобится на 1 000 элементов?».
Рассмотрим по порядку возрастания сложности все варианты:
⦁	О(1)— в этом случае у нас нет числа n, как нет и зависимости от количества элементов. Такая оценка
может быть, например, у алгоритмов, которые выполняют действие над одним элементом, допустим извлекают
одну букву из строки. В строке может быть миллиард букв, а может быть десять, но первую букву мы всегда
сможем извлечь за одно действие.
⦁	О(log n)— log может пугать, но достаточно просто запомнить, что эта оценка быстрее линейной зависимости.
Если при линейной зависимости на 128 элементов мы потратим 128 действий, то при O(log n):
log 128 = 7 — нам понадобится всего семь действий.
Количество действий будет расти с количеством элементов, но происходить это будет гораздо медленнее.
⦁	O(n)— линейная оценка, самая простая (но не самая эффективная, как мы видели ранее).
Сколько элементов — столько и действий.
⦁	О(n * log n)— пожалуй, самая длинная из вариантов, она говорит о том, что алгоритм работает медленнее,
чем при линейной оценке. Можем пересчитать пример со 128 элементами:
n * log (n) = 128 * 7 = 896.
Получается значительная разница (и чем больше элементов — тем она будет существеннее).
⦁	О(n^2)— квадратичная зависимость, она ещё более медленная, чем предыдущая. Если там мы умножали
128 * 7, здесь нам пришлось бы умножать 128 на 128 (128^2 = 128 * 128 = 16 384).
⦁	О(n!)— самая медленная оценка из базовых — факториал от числа элементов, который надо обработать. Для
обработки 128 элементов пришлось бы считать следующую цепочку:
1 * 2 * 3 * … * 127 * 128 ~ 3,85 * 10 ** 215 — это число уже на много порядков больше даже предыдущего
большого числа.

Пример
Допустим, наша задача — разделить лист бумаги на 16/256/1024 прямоугольников.
Пусть компьютер выполняет десять операций в секунду. Если мы выберем для решения задачи алгоритм со
сложностью O(log n), то для получения 16 прямоугольников нам понадобится всего четыре операции, и они
выполнятся за 0,4 с.
На изображении ниже можно увидеть, за какое время мы выполним эту же задачу сразным количеством
прямоугольников разными алгоритмами:

Изображение: иллюстрация из книги «Грокаем алгоритмы». Автор — Адитья Бхаргава
Ждать много лет лист с 16 прямоугольниками было бы крайне обидно— согласитесь?


